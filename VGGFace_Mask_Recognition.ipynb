{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cIXwbyKl4YCG8rzKlfNmT_qblrZ5L2qF",
      "authorship_tag": "ABX9TyP2/HafgZIOhd8WacAiXcOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDfarazuddin99/Face_Masked_Recognition/blob/master/VGGFace_Mask_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTxs8Y5H4QDK",
        "colab_type": "code",
        "outputId": "cb5b193a-aa7a-4374-a424-caed14047ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-6ipqzg3u\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-6ipqzg3u\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=7ecbe92f7c6dcdaba1bd702ba1b847f4a8f3efb77cabfe13356f6a59095ca615\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-meqzcqjk/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1EnfUl04VvL",
        "colab_type": "code",
        "outputId": "9785904e-66d1-4f67-cbbf-2f029eab2eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "pip install keras_vggface"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.18.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras_vggface) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras_vggface) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANksR0y84dpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "# Based on VGG16 architecture -> old paper(2015)\n",
        "vggface = VGGFace(model='vgg16') # or VGGFace() as default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHm6mN574mU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine import  Model\n",
        "from keras.layers import Flatten, Dense, Input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "#custom parameters\n",
        "nb_class = 2\n",
        "hidden_dim = 512\n",
        "\n",
        "vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3),pooling='avg')\n",
        "last_layer = vgg_model.get_layer('pool5').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
        "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
        "custom_vgg_model = Model(vgg_model.input, out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eraKfCrf5MLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_count = 0\n",
        "for layer in custom_vgg_model.layers:\n",
        "\tlayer_count = layer_count+1\n",
        "\n",
        "for l in range(layer_count-8):\n",
        "\tcustom_vgg_model.layers[l].trainable=False\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgXmElVvkhl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_vgg_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWpjpboB4FXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_vggface import utils\n",
        "preprocess_input = utils.preprocess_input\n",
        "datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTfVxz5S4oS7",
        "colab_type": "code",
        "outputId": "0b6ce25c-b5ac-4af6-f856-0d81d0f186d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "image_size = 224\n",
        "train_generator = datagenerator.flow_from_directory(\n",
        "        '/content/drive/My Drive/Custom/train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=16,\n",
        "        class_mode='categorical',)\n",
        "\n",
        "validation_generator = datagenerator.flow_from_directory(\n",
        "        '/content/drive/My Drive/Custom/test',\n",
        "        target_size=(image_size, image_size),\n",
        "        class_mode='categorical')\n",
        "\n",
        "custom_vgg_model.fit_generator(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=1,epochs=20)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 39 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 44.8023 - accuracy: 0.6410 - val_loss: 14.6958 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 4.4880 - accuracy: 0.7949 - val_loss: 74.6913 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 12.0759 - accuracy: 0.7436 - val_loss: 3.8053 - val_accuracy: 0.9500\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 4.7749 - accuracy: 0.9487 - val_loss: 8.9575 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 3.8203 - accuracy: 0.9744 - val_loss: 165.1364 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 6.8979 - accuracy: 0.9744 - val_loss: 5.0410 - val_accuracy: 0.9000\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 5.2362 - accuracy: 0.9744 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 79.8180 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.4003 - accuracy: 0.9744 - val_loss: 11.9113 - val_accuracy: 0.9500\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 3.5486 - accuracy: 0.9744 - val_loss: 579.0201 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.0633 - accuracy: 0.9744 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 9.2108 - accuracy: 0.9744 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 120.5327 - accuracy: 0.9231 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 225.0194 - val_accuracy: 0.9500\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 129.5879 - accuracy: 0.9744 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2606.0115 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 52.6490 - accuracy: 0.9744 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1546.3280 - val_accuracy: 0.9000\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 53.2979 - accuracy: 0.9744 - val_loss: 161.9899 - val_accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f9b0cf2b978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fncD_rB3EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from IPython.display import display, Javascript\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "# def take_photo(filename='photo.jpg', quality=0.8):\n",
        "#   js = Javascript('''\n",
        "#     async function takePhoto(quality) {\n",
        "#       const div = document.createElement('div');\n",
        "#       const capture = document.createElement('button');\n",
        "#       capture.textContent = 'Capture';\n",
        "#       div.appendChild(capture);\n",
        "\n",
        "#       const video = document.createElement('video');\n",
        "#       video.style.display = 'block';\n",
        "#       const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "#       document.body.appendChild(div);\n",
        "#       div.appendChild(video);\n",
        "#       video.srcObject = stream;\n",
        "#       await video.play();\n",
        "\n",
        "#       // Resize the output to fit the video element.\n",
        "#       google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "#       // Wait for Capture to be clicked.\n",
        "#       await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "#       const canvas = document.createElement('canvas');\n",
        "#       canvas.width = video.videoWidth;\n",
        "#       canvas.height = video.videoHeight;\n",
        "#       canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "#       stream.getVideoTracks()[0].stop();\n",
        "#       div.remove();\n",
        "#       return canvas.toDataURL('image/jpeg', quality);\n",
        "#     }\n",
        "#     ''')\n",
        "#   display(js)\n",
        "#   data = eval_js('takePhoto({})'.format(quality))\n",
        "#   binary = b64decode(data.split(',')[1])\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(binary)\n",
        "#   return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cTM05RFscR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from IPython.display import Image\n",
        "# try:\n",
        "#   filename = take_photo()\n",
        "#   print('Saved to {}'.format(filename))\n",
        "  \n",
        "#   # Show the image which was just taken.\n",
        "#   display(Image(filename))\n",
        "# except Exception as err:\n",
        "#   # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "#   # grant the page permission to access it.\n",
        "#   print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUzFsIEAFvlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "95e532bb-6c13-4a07-f2fc-63e966408c81"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "test_path = input()\n",
        "img = image.load_img(test_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = utils.preprocess_input(x, version=1) # or version=2\n",
        "preds = custom_vgg_model.predict(x)\n",
        "print(preds)\n",
        "if preds[0][0]>preds[0][1]:\n",
        "    print('Faraz')\n",
        "else:\n",
        "    print('Farha')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/test_2.jpg\n",
            "[[0. 1.]]\n",
            "Farha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfwEIlCekDUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}