{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cIXwbyKl4YCG8rzKlfNmT_qblrZ5L2qF",
      "authorship_tag": "ABX9TyPmqfSIpg0QXTbaqXE+AQ6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDfarazuddin99/Face_Masked_Recognition/blob/master/Mask_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTxs8Y5H4QDK",
        "colab_type": "code",
        "outputId": "4a13873e-9722-46f2-b8b3-d2c1280c8fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-l3eb5233\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-l3eb5233\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=a4bc7e78747571dc1ef9ec54c79f26669939b7c86d2bb1b0314840d53a5be20b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ot6u2xxc/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1EnfUl04VvL",
        "colab_type": "code",
        "outputId": "fe0b0b0b-7b0d-40c1-c480-96b9accf1dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "pip install keras_vggface"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (7.0.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.18.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras_vggface) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras_vggface) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANksR0y84dpM",
        "colab_type": "code",
        "outputId": "14325185-ff5a-4cca-aebc-991a6be896d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "# Based on VGG16 architecture -> old paper(2015)\n",
        "vggface = VGGFace(model='vgg16') # or VGGFace() as default"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHm6mN574mU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine import  Model\n",
        "from keras.layers import Flatten, Dense, Input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "#custom parameters\n",
        "nb_class = 4\n",
        "\n",
        "hidden_dim = 256\n",
        "\n",
        "vgg_model = VGGFace(include_top=False, input_shape=(128, 128, 3),pooling='avg')\n",
        "last_layer = vgg_model.get_layer('pool5').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
        "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
        "custom_vgg_model = Model(vgg_model.input, out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eraKfCrf5MLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_count = 0\n",
        "for layer in custom_vgg_model.layers:\n",
        "\tlayer_count = layer_count+1\n",
        "\n",
        "for l in range(layer_count-3):\n",
        "\tcustom_vgg_model.layers[l].trainable=False\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgXmElVvkhl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_vgg_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWpjpboB4FXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_vggface import utils\n",
        "preprocess_input = utils.preprocess_input\n",
        "datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTfVxz5S4oS7",
        "colab_type": "code",
        "outputId": "ba7b73d7-284d-4b04-b51a-e33bc3a92c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "image_size = 128\n",
        "train_generator = datagenerator.flow_from_directory(\n",
        "        '/content/drive/My Drive/5-celebrity-faces-dataset/custom_data/train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',)\n",
        "\n",
        "validation_generator = datagenerator.flow_from_directory(\n",
        "        '/content/drive/My Drive/5-celebrity-faces-dataset/custom_data/test',\n",
        "        target_size=(image_size, image_size),\n",
        "        class_mode='categorical')\n",
        "\n",
        "custom_vgg_model.fit_generator(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=2,epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 71 images belonging to 4 classes.\n",
            "Found 20 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 4.3897e-04 - accuracy: 1.0000 - val_loss: 13.4970 - val_accuracy: 0.6500\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 2.7646e-05 - accuracy: 1.0000 - val_loss: 14.0070 - val_accuracy: 0.6500\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 163ms/step - loss: 4.0773e-06 - accuracy: 1.0000 - val_loss: 14.3881 - val_accuracy: 0.6500\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 1.8185e-06 - accuracy: 1.0000 - val_loss: 14.7261 - val_accuracy: 0.6500\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 1.6658e-06 - accuracy: 1.0000 - val_loss: 14.9924 - val_accuracy: 0.6500\n",
            "Epoch 6/20\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 3.2782e-07 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFexM1Po-LTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "test_path = input()\n",
        "img = image.load_img(test_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = utils.preprocess_input(x, version=1) # or version=2\n",
        "preds = custom_vgg_model.predict(x)\n",
        "print(preds)\n",
        "if preds[0][0]>preds[0][1]:\n",
        "    print('Faraz')\n",
        "else:\n",
        "    print('Farha')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PJPX7pl5aIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}